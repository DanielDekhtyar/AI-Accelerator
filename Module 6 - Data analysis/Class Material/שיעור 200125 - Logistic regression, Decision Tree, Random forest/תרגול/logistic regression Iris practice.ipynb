{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dc67fd-4fca-4be4-8507-b0b2ed148937",
   "metadata": {},
   "source": [
    "## Exercise: Classification with the Iris Dataset\r\n",
    "\r\n",
    "### **Objective**\r\n",
    "In this exercise, you will work with the Iris dataset to perform a classification task. You will:\r\n",
    "1. Perform exploratory data analysis (EDA).\r\n",
    "2. Train a logistic regression model.\r\n",
    "3. Evaluate the model's performance.\r\n",
    "4. Compare results with and without feature scaling.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### **Step 1: Import Libraries**\r\n",
    "Begin by importing the necesss:\n",
    "pandas, numpy, seaborn, matplotlib.pyplot\n",
    "and \n",
    "\n",
    "#from sklearn.datasets import load_iris #your data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrixary librarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d33557-253e-425d-bf04-40596c0d0705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eacf92da-ce92-40b3-bd53-71c978903cda",
   "metadata": {},
   "source": [
    "---\n",
    "### **Step 2: Load hte `Iris` Dataset**\n",
    "use seaborn, confirm the data has been loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58067634-3ef0-491b-b4e1-154055eaa6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "866411e4-0718-4e46-ae14-345f8185a468",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Step 3: Initial EDA**\n",
    "Perform exploratory data analysis to understand the dataset:\n",
    "1. Check for missing values:\n",
    "   \n",
    "2. Check data types to ensure all features are numeric:\n",
    "   \n",
    "3. Visualize the distributions of the features\n",
    "4. (use pairplot, color the data by the `species` target column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d1bc3-540c-4c2f-ad4f-26dcabaac85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77c939-7c20-4be1-bf7d-aa8af033a045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518d303-2b8b-4bc3-9995-ef15c490d164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab71d1e8-10f8-4048-a512-f73b1193e380",
   "metadata": {},
   "source": [
    "---\n",
    "### **Step 4: Preprocessing and Model Training**\n",
    "#### **Part A: Without Scaling**  \n",
    "1.use the folowing command to alter the `species` column\n",
    "```python\n",
    "df['species'] =df['species'].astype('category').cat.codes\n",
    "```\n",
    "2. Split the data to training and testing groups.\n",
    "   * use random_state = 2. (if you have time try using random_states 7 and 42 to compare)\n",
    "4. Train a logistic regression model on the data\n",
    "5. Evaluate the scaled model using accuracy_score and confussion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1ee29-ff5e-41dd-84f0-22df0e3c6d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c4719-bf06-4368-93a6-650c3f8ad250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328aa54-69ab-485f-8b61-68ca039625a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a logistic regression  if needed use max_iter=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb5159-f3e7-476d-a108-4edbf815a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70febf08-fcfe-4496-bac8-d937900d7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375f016-15c2-49c2-b5be-f13ef3ebcb63",
   "metadata": {},
   "source": [
    "\n",
    "\r\n",
    "#### **Part B: With Scaling**\r\n",
    "1. Apply scaling to the featur\n",
    "2. Train a logistic regression model on the scaled data:\n",
    "3. Evaluate the scaled model:s:nalyze your results carefully!\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cac9e0-3cef-4ff9-8316-cbcd45765214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debb035-2ff5-4e52-a814-21c11b3ea214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redo the rest..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
